{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "\n",
    "#numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pd.read_csv('data/application_train.csv')\n",
    "bureau = pd.read_csv('data/bureau.csv')\n",
    "bureau_balance = pd.read_csv('data/bureau_balance.csv')\n",
    "previous_app = pd.read_csv('data/previous_application.csv')\n",
    "credit_card_balance = pd.read_csv('data/credit_card_balance.csv')\n",
    "pos_cash_balance = pd.read_csv('data/POS_CASH_balance.csv')\n",
    "installments_payments = pd.read_csv('data/installments_payments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 columns were label encoded.\n"
     ]
    }
   ],
   "source": [
    "# Create an anomalous flag column\n",
    "app['DAYS_EMPLOYED_ANOM'] = app[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "# Replace the anomalous values with nan\n",
    "app['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "# Treating as outlier and removing\n",
    "app = app[app['CODE_GENDER'] != 'XNA']\n",
    "\n",
    "app['CREDIT_INCOME_PERCENT'] = app['AMT_CREDIT'] / app['AMT_INCOME_TOTAL']\n",
    "app['ANNUITY_INCOME_PERCENT'] = app['AMT_ANNUITY'] / app['AMT_INCOME_TOTAL']\n",
    "app['CREDIT_TERM'] = app['AMT_ANNUITY'] / app['AMT_CREDIT']\n",
    "app['DAYS_EMPLOYED_PERCENT'] = app['DAYS_EMPLOYED'] / app['DAYS_BIRTH']\n",
    "\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in app:\n",
    "    if app[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(app[col])\n",
    "            # Transform \n",
    "            app[col] = le.transform(app[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_day_outliers(df):\n",
    "    \"\"\"Replace 365243 with np.nan in any columns with DAYS\"\"\"\n",
    "    for col in df.columns:\n",
    "        if \"DAYS\" in col:\n",
    "            if len(df[df[col]==365243]) > 0:\n",
    "                df[col] = df[col].replace({365243: df[col].mean()})\n",
    "                df[col+'_ANOM'] = df[col] == 365243\n",
    "    return df\n",
    "\n",
    "bureau = replace_day_outliers(bureau)\n",
    "bureau_balance = replace_day_outliers(bureau_balance)\n",
    "previous_app = replace_day_outliers(previous_app)\n",
    "credit_card_balance = replace_day_outliers(credit_card_balance)\n",
    "pos_cash_balance = replace_day_outliers(pos_cash_balance)\n",
    "installments_payments = replace_day_outliers(installments_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(app.memory_usage().sum() / 1e9, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Memory Usage: 0.31 gb.\n",
      "New Memory Usage: 0.14 gb.\n",
      "Original Memory Usage: 0.23 gb.\n",
      "New Memory Usage: 0.1 gb.\n",
      "Original Memory Usage: 0.66 gb.\n",
      "New Memory Usage: 0.25 gb.\n",
      "Original Memory Usage: 0.5 gb.\n",
      "New Memory Usage: 0.17 gb.\n",
      "Original Memory Usage: 0.71 gb.\n",
      "New Memory Usage: 0.34 gb.\n",
      "Original Memory Usage: 0.64 gb.\n",
      "New Memory Usage: 0.29 gb.\n",
      "Original Memory Usage: 0.87 gb.\n",
      "New Memory Usage: 0.44 gb.\n"
     ]
    }
   ],
   "source": [
    "def return_size(df):\n",
    "    \"\"\"Return size of dataframe in gigabytes\"\"\"\n",
    "    return round(sys.getsizeof(df) / 1e9, 2)\n",
    "\n",
    "def convert_types(df, print_info = False):\n",
    "    \n",
    "    original_memory = df.memory_usage().sum()\n",
    "    \n",
    "    # Iterate through each column\n",
    "    for c in df:\n",
    "        \n",
    "        # Convert ids and booleans to integers\n",
    "        if ('SK_ID' in c):\n",
    "            df[c] = df[c].fillna(0).astype(np.int32)\n",
    "            \n",
    "        # Convert objects to category\n",
    "        elif (df[c].dtype == 'object') and (df[c].nunique() < df.shape[0]):\n",
    "            df[c] = df[c].astype('category')\n",
    "        \n",
    "        # Booleans mapped to integers\n",
    "        elif list(df[c].unique()) == [1, 0]:\n",
    "            df[c] = df[c].astype(bool)\n",
    "        \n",
    "        # Float64 to float32\n",
    "        elif df[c].dtype == float:\n",
    "            df[c] = df[c].astype(np.float32)\n",
    "            \n",
    "        # Int64 to int32\n",
    "        elif df[c].dtype == int:\n",
    "            df[c] = df[c].astype(np.int32)\n",
    "        \n",
    "    new_memory = df.memory_usage().sum()\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'Original Memory Usage: {round(original_memory / 1e9, 2)} gb.')\n",
    "        print(f'New Memory Usage: {round(new_memory / 1e9, 2)} gb.')\n",
    "        \n",
    "    return df\n",
    "\n",
    "app = convert_types(app, True)\n",
    "bureau = convert_types(bureau, True)\n",
    "bureau_balance = convert_types(bureau_balance, True)\n",
    "previous_app = convert_types(previous_app, True)\n",
    "credit_card_balance = convert_types(credit_card_balance, True)\n",
    "pos_cash_balance = convert_types(pos_cash_balance, True)\n",
    "installments_payments = convert_types(installments_payments, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(app.memory_usage().sum() / 1e9, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application features : 127\n"
     ]
    }
   ],
   "source": [
    "def aggregate_numeric_data(df, parent_var, df_name):\n",
    "    \"\"\"\n",
    "    Groups and aggregates the numeric values in a child dataframe\n",
    "    by the parent variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        df (dataframe): \n",
    "            the child dataframe to calculate the statistics on\n",
    "        parent_var (string): \n",
    "            the parent variable used for grouping and aggregating\n",
    "        df_name (string): \n",
    "            the variable used to rename the columns\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        agg (dataframe): \n",
    "            a dataframe with the statistics aggregated by the `parent_var` for \n",
    "            all numeric columns. Each observation of the parent variable will have \n",
    "            one row in the dataframe with the parent variable as the index. \n",
    "            The columns are also renamed using the `df_name`. Columns with all duplicate\n",
    "            values are removed. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove id variables other than grouping variable\n",
    "    for col in df:\n",
    "        if col != parent_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns = col)\n",
    "            \n",
    "    # Only want the numeric variables\n",
    "    parent_ids = df[parent_var].copy()\n",
    "    numeric_df = df.select_dtypes('number').copy()\n",
    "    numeric_df[parent_var] = parent_ids\n",
    "\n",
    "    # Group by the specified variable and calculate the statistics\n",
    "    agg = numeric_df.groupby(parent_var).agg(['count', 'mean', 'max', 'min', 'sum'])\n",
    "\n",
    "    # Need to create new column names\n",
    "    columns = []\n",
    "\n",
    "    # Iterate through the variables names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        if var != parent_var:\n",
    "            # Iterate through the stat names\n",
    "            for stat in agg.columns.levels[1]:\n",
    "                # Make a new column name for the variable and stat\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    \n",
    "    agg.columns = columns\n",
    "    \n",
    "    # Remove the columns with all redundant values\n",
    "    _, idx = np.unique(agg, axis = 1, return_index=True)\n",
    "    agg = agg.iloc[:, idx]\n",
    "    \n",
    "    return agg\n",
    "\n",
    "\n",
    "\n",
    "def aggregate_categorical_data(df, parent_var, df_name):\n",
    "    \"\"\"\n",
    "    Aggregates the categorical features in a child dataframe\n",
    "    for each observation of the parent variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe \n",
    "        The dataframe to calculate the value counts for.\n",
    "        \n",
    "    parent_var : string\n",
    "        The variable by which to group and aggregate the dataframe. For each unique\n",
    "        value of this variable, the final dataframe will have one row\n",
    "        \n",
    "    df_name : string\n",
    "        Variable added to the front of column names to keep track of columns\n",
    "\n",
    "    \n",
    "    Return\n",
    "    --------\n",
    "    categorical : dataframe\n",
    "        A dataframe with aggregated statistics for each observation of the parent_var\n",
    "        The columns are also renamed and columns with duplicate values are removed.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the categorical columns\n",
    "    categorical = pd.get_dummies(df.select_dtypes('category'))\n",
    "\n",
    "    # Make sure to put the identifying id on the column\n",
    "    categorical[parent_var] = df[parent_var]\n",
    "\n",
    "    # Groupby the group var and calculate the sum and mean\n",
    "    categorical = categorical.groupby(parent_var).agg(['sum', 'count', 'mean'])\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    # Iterate through the columns in level 0\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        # Iterate through the stats in level 1\n",
    "        for stat in ['sum', 'count', 'mean']:\n",
    "            # Make a new column name\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    \n",
    "    categorical.columns = column_names\n",
    "    \n",
    "    # Remove duplicate columns by values\n",
    "    _, idx = np.unique(categorical, axis = 1, return_index = True)\n",
    "    categorical = categorical.iloc[:, idx]\n",
    "    \n",
    "    return categorical\n",
    "\n",
    "print(\"Application features : {}\".format(len(app.columns)))\n",
    "\n",
    "bureau_agg_num = aggregate_numeric_data(bureau.drop(columns = ['SK_ID_BUREAU']), \n",
    "                                        parent_var = 'SK_ID_CURR', df_name = 'bureau')\n",
    "bureau_agg_cat = aggregate_categorical_data(bureau.drop(columns = ['SK_ID_BUREAU']),\n",
    "                                   parent_var = 'SK_ID_CURR', df_name = 'bureau')\n",
    "bureau_balance_agg_num = aggregate_numeric_data(bureau_balance, parent_var = 'SK_ID_BUREAU',\n",
    "                                                df_name = 'bureau_balance')\n",
    "bureau_balance_agg_cat = aggregate_categorical_data(bureau_balance, parent_var = 'SK_ID_BUREAU',\n",
    "                                                df_name = 'bureau_balance')\n",
    "monthly_bureau_data = bureau_balance_agg_num.merge(bureau_balance_agg_cat,right_index=True,\n",
    "                                                   left_on='SK_ID_BUREAU' ,how='outer')\n",
    "monthly_bureau_data = monthly_bureau_data.merge(bureau[['SK_ID_BUREAU', 'SK_ID_CURR']], \n",
    "                                               on='SK_ID_BUREAU',how='left')\n",
    "client_bureau_balance = aggregate_numeric_data(monthly_bureau_data.drop(columns = ['SK_ID_BUREAU']),\n",
    "                                    parent_var = 'SK_ID_CURR', df_name = 'client')\n",
    "\n",
    "\n",
    "app = app.merge(bureau_agg_num, on = 'SK_ID_CURR', how = 'left')\n",
    "app = app.merge(bureau_agg_cat, on = 'SK_ID_CURR', how = 'left')\n",
    "app = app.merge(client_bureau_balance, on = 'SK_ID_CURR', how = 'left')\n",
    "previous_app_agg_num = aggregate_numeric_data(previous_app, 'SK_ID_CURR', 'previous')\n",
    "previous_app_agg_cat = aggregate_categorical_data(previous_app, 'SK_ID_CURR', 'previous')\n",
    "app = app.merge(previous_app_agg_num, on ='SK_ID_CURR', how = 'left')\n",
    "app = app.merge(previous_app_agg_cat, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(338857, 80)\n",
      "(338857, 285)\n",
      "(134542, 85)\n"
     ]
    }
   ],
   "source": [
    "print(previous_app_agg_num.shape)\n",
    "print(previous_app_agg_cat.shape)\n",
    "print(client_bureau_balance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_by_client(df, group_vars, df_names):\n",
    "    \"\"\"Aggregate a dataframe with data at the loan level \n",
    "    at the client level\n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): data at the loan level\n",
    "        group_vars (list of two strings): grouping variables for the loan \n",
    "        and then the client (example ['SK_ID_PREV', 'SK_ID_CURR'])\n",
    "        names (list of two strings): names to call the resulting columns\n",
    "        (example ['cash', 'client'])\n",
    "        \n",
    "    Returns:\n",
    "        df_client (dataframe): aggregated numeric stats at the client level. \n",
    "        Each client will have a single row with all the numeric data aggregated\n",
    "    \"\"\"\n",
    "    \n",
    "    # Aggregate the numeric columns\n",
    "    df_agg = aggregate_numeric_data(df, parent_var = group_vars[0], df_name = df_names[0])\n",
    "    \n",
    "    # If there are categorical variables\n",
    "    if any(df.dtypes == 'category'):\n",
    "    \n",
    "        # Aggregate the categorical columns\n",
    "        df_counts = aggregate_categorical_data(df, parent_var = group_vars[0], df_name = df_names[0])\n",
    "\n",
    "        # Merge the numeric and categorical\n",
    "        df_by_loan = df_counts.merge(df_agg, on = group_vars[0], how = 'outer')\n",
    "\n",
    "        gc.enable()\n",
    "        del df_agg, df_counts\n",
    "        gc.collect()\n",
    "\n",
    "        # Merge to get the client id in dataframe\n",
    "        df_by_loan = df_by_loan.merge(df[[group_vars[0], group_vars[1]]], on = group_vars[0], how = 'left')\n",
    "\n",
    "        # Remove the loan id\n",
    "        df_by_loan = df_by_loan.drop(columns = [group_vars[0]])\n",
    "\n",
    "        # Aggregate numeric stats by column\n",
    "        df_by_client = aggregate_numeric_data(df_by_loan, parent_var = group_vars[1], df_name = df_names[1])\n",
    "\n",
    "        \n",
    "    # No categorical variables\n",
    "    else:\n",
    "        # Merge to get the client id in dataframe\n",
    "        df_by_loan = df_agg.merge(df[[group_vars[0], group_vars[1]]], on = group_vars[0], how = 'left')\n",
    "        \n",
    "        gc.enable()\n",
    "        del df_agg\n",
    "        gc.collect()\n",
    "        \n",
    "        # Remove the loan id\n",
    "        df_by_loan = df_by_loan.drop(columns = [group_vars[0]])\n",
    "        \n",
    "        # Aggregate numeric stats by column\n",
    "        df_by_client = aggregate_numeric_data(df_by_loan, parent_var = group_vars[1], df_name = df_names[1])\n",
    "        \n",
    "    # Memory management\n",
    "    gc.enable()\n",
    "    del df, df_by_loan\n",
    "    gc.collect()\n",
    "\n",
    "    return df_by_client\n",
    "\n",
    "credit_card_bal_agg = aggregate_by_client(credit_card_balance, group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], \n",
    "                                  df_names = ['credit', 'client'])\n",
    "pos_cash_bal_agg = aggregate_by_client(pos_cash_balance, group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], \n",
    "                                  df_names = ['cash', 'client'])\n",
    "installments_agg = aggregate_by_client(installments_payments, group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], \n",
    "                                  df_names = ['installments', 'client'])\n",
    "app = app.merge(credit_card_bal_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "app = app.merge(pos_cash_bal_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "app = app.merge(installments_agg, on = 'SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307507, 1332)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_columns = [x for x in app.columns if 'SK_ID_CURR' in x or 'SK_ID_PREV' in x or 'SK_ID_BUREAU' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307507, 1332)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = app.drop(columns=id_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307507, 1331)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.to_csv('training.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
