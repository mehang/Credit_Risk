{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('data/application_train.csv')\n",
    "# # Create an anomalous flag column\n",
    "samples['DAYS_EMPLOYED_ANOM'] = samples[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "# # # Replace the anomalous values with nan\n",
    "samples['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "# Treating as outlier and removing\n",
    "samples = samples[samples['CODE_GENDER'] != 'XNA']\n",
    "\n",
    "train_label = samples['TARGET']\n",
    "train_data = samples.drop(columns=['TARGET'])\n",
    "\n",
    "correlations = samples.corr()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = correlations.where(np.triu(np.ones(correlations.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.99)]\n",
    "\n",
    "# Drop highly correlated features\n",
    "train_data = train_data.drop(train_data[to_drop], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 columns were label encoded.\n"
     ]
    }
   ],
   "source": [
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in train_data:\n",
    "    if train_data[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(train_data[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(train_data[col])\n",
    "            # Transform \n",
    "            train_data[col] = le.transform(train_data[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of categorical variables\n",
    "train_data = pd.get_dummies(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['CREDIT_INCOME_PERCENT'] = train_data['AMT_CREDIT'] / train_data['AMT_INCOME_TOTAL']\n",
    "train_data['ANNUITY_INCOME_PERCENT'] = train_data['AMT_ANNUITY'] / train_data['AMT_INCOME_TOTAL']\n",
    "train_data['CREDIT_TERM'] = train_data['AMT_ANNUITY'] / train_data['AMT_CREDIT']\n",
    "train_data['DAYS_EMPLOYED_PERCENT'] = train_data['DAYS_EMPLOYED'] / train_data['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307507, 230)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Median imputation of missing values\n",
    "imputer = SimpleImputer(strategy = 'median')\n",
    "\n",
    "# Scale each feature to 0-1\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "# Fit on the training data\n",
    "imputer.fit(train_data)\n",
    "\n",
    "# Transform both training and testing data\n",
    "train_data = imputer.transform(train_data)\n",
    "\n",
    "# Repeat with the scaler\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "\n",
    "print('Training data shape: ', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test, y_train, y_test = train_test_split(train_data, train_label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Make the model with the specified regularization parameter\n",
    "\n",
    "# 80-20 train-test case\n",
    "kf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "log_reg = LogisticRegression(C = 0.001, max_iter=100, solver='sag', fit_intercept=True,\n",
    "                             class_weight='balanced')\n",
    "y_pred = cross_val_predict(estimator=log_reg , X=x_train, y=y_train, cv=kf, method='predict_proba')\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# print(metrics.confusion_matrix(y_train, y_pred))\n",
    "# print(metrics.classification_report(train_label ,y_pred))\n",
    "# print(\"roc - {}\".format(metrics.roc_auc_score(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6451454 , 0.3548546 ],\n",
       "       [0.35189698, 0.64810302],\n",
       "       [0.53853605, 0.46146395],\n",
       "       ...,\n",
       "       [0.5328944 , 0.4671056 ],\n",
       "       [0.37136355, 0.62863645],\n",
       "       [0.43653138, 0.56346862]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 36.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 45.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 53.5min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 61.2min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 62.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=8)]: Done 10000 out of 10000 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 49.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 57.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 65.7min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 67.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:  4.1min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tot_trees = [10000]\n",
    "for tot_tree in tot_trees:\n",
    "    kf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "    random_forest = RandomForestClassifier(n_estimators = tot_tree, class_weight='balanced', random_state = 50, verbose = 1, n_jobs = -1)\n",
    "    y_pred = cross_val_predict(estimator=random_forest, X=x_train, y=y_train, cv=kf)\n",
    "    print(\"Number of trees - {}  roc - {}\".format(tot_tree,metrics.roc_auc_score(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3548545964872827"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prediction(arr):\n",
    "    return [ for _y_predic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc - 0.6758773151208118\n"
     ]
    }
   ],
   "source": [
    "def classify(arr, threshold=0.5):\n",
    "    return [1 if _y_pred[1]>=threshold else 0  for _y_pred in y_pred]\n",
    "jpt = [1 if _y_pred[1]>=0.5 else 0  for _y_pred in y_pred]\n",
    "print(\"roc - {}\".format(metrics.roc_auc_score(y_train, jpt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[154276  71894]\n",
      " [  6527  13308]]\n",
      "roc - 0.6765296407480921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Make the model with the specified regularization parameter\n",
    "\n",
    "# 80-20 train-test case\n",
    "kf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "log_reg = LogisticRegression(C = 0.001, max_iter=100, solver='sag', fit_intercept=True,\n",
    "                             class_weight='balanced')\n",
    "y_pred = cross_val_predict(estimator=log_reg , X=x_train, y=y_train, cv=kf)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_train, y_pred))\n",
    "# print(metrics.classification_report(train_label ,y_pred))\n",
    "print(\"roc - {}\".format(metrics.roc_auc_score(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38637 17875]\n",
      " [ 1679  3311]]\n",
      "roc - 0.673611276204731\n"
     ]
    }
   ],
   "source": [
    "final_log = LogisticRegression(C = 0.001, max_iter=100, solver='sag', fit_intercept=True,\n",
    "                             class_weight='balanced')\n",
    "final_log.fit(x_train, y_train)\n",
    "test_pred = final_log.predict(x_test)\n",
    "print(metrics.confusion_matrix(y_test, test_pred))\n",
    "print(\"roc - {}\".format(metrics.roc_auc_score(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[226006    164]\n",
      " [ 19681    154]]\n",
      "roc - 0.5035194675835113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# 80-20 train-test case\n",
    "mlp_kf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "#mean of number of hidden nodes(1 layer is enough for) between input nodes and output nodes\n",
    "total_hidden_nodes = int((2 + (len(samples.columns)-1))/2)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(total_hidden_nodes-10,),activation='logistic', solver='sgd', \n",
    "                    batch_size=400, learning_rate_init=0.01, max_iter=200, alpha=0.0001)\n",
    "y_pred = cross_val_predict(estimator=mlp , X=x_train, y=y_train, cv=mlp_kf)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_train, y_pred))\n",
    "# print(metrics.classification_report(train_label ,y_pred))\n",
    "print(\"roc - {}\".format(metrics.roc_auc_score(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56490    22]\n",
      " [ 4972    18]]\n",
      "roc - 0.5016089582903066\n"
     ]
    }
   ],
   "source": [
    "final_mlp = MLPClassifier(hidden_layer_sizes=(total_hidden_nodes-10,),activation='logistic', solver='sgd', \n",
    "                    batch_size=400, learning_rate_init=0.01, max_iter=200, alpha=0.0001)\n",
    "final_mlp.fit(x_train, y_train)\n",
    "test_pred = final_mlp.predict(x_test)\n",
    "print(metrics.confusion_matrix(y_test, test_pred))\n",
    "print(\"roc - {}\".format(metrics.roc_auc_score(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307507, 230)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.astype(int).plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246005,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61502,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
